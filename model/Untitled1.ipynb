{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dAfJsX-tD-VZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import re\n",
        "import json\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Abkghhe4IKjp",
        "outputId": "4e5fa204-8f86-4fae-e61a-89d78070ef35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8P6YtMD0cc-N"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D-US0iQcT4V",
        "outputId": "557d0aa1-763c-4360-cf26-97638f30beb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: neo4j in /usr/local/lib/python3.11/dist-packages (5.28.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from neo4j) (2025.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langdetect\n",
        "!pip install neo4j\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg7za5jVdC3C"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioVanS57ckwd",
        "outputId": "a8c05273-f1e5-42b1-f4eb-da908559a9bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'alert': 'No Data', 'confidence': 0, 'summary': 'No relevant fact-checks found.', 'source': None}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Google Fact Check API\n",
        "GOOGLE_API_KEY = \"AIzaSyDNeMBludw0zfbeRf2yZ1Adcy1bgwIyYYc\"\n",
        "FACTCHECK_URL = \"https://factchecktools.googleapis.com/v1alpha1/claims:search\"\n",
        "\n",
        "# Load SentenceTransformer Model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def fetch_fact_check(query):\n",
        "    \"\"\"Fetches fact-check results from Google Fact Check API (English only)\"\"\"\n",
        "    params = {\"query\": query, \"key\": GOOGLE_API_KEY, \"languageCode\": \"en\"}\n",
        "    response = requests.get(FACTCHECK_URL, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        if \"claims\" in data:\n",
        "            return [\n",
        "                {\n",
        "                    \"text\": claim[\"text\"],\n",
        "                    \"verdict\": claim[\"claimReview\"][0][\"textualRating\"],\n",
        "                    \"source\": claim[\"claimReview\"][0][\"url\"]\n",
        "                }\n",
        "                for claim in data[\"claims\"]\n",
        "            ]\n",
        "    return []\n",
        "\n",
        "def process_fact_checking_results(claim):\n",
        "    fact_results = fetch_fact_check(claim)\n",
        "\n",
        "    if not fact_results:\n",
        "        return {\"alert\": \"No Data\", \"confidence\": 0, \"summary\": \"No relevant fact-checks found.\", \"source\": None}\n",
        "\n",
        "    claim_embedding = model.encode(claim, convert_to_tensor=True)\n",
        "    scores = []\n",
        "\n",
        "    for fact in fact_results:\n",
        "        fact_text = fact[\"text\"]\n",
        "        fact_embedding = model.encode(fact_text, convert_to_tensor=True)\n",
        "        similarity = util.pytorch_cos_sim(claim_embedding, fact_embedding).item()\n",
        "        scores.append((fact, similarity))\n",
        "\n",
        "    scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    top_scores = [score[1] for score in scores[:3]]\n",
        "    confidence = int(np.mean(top_scores) * 100) if top_scores else 0\n",
        "\n",
        "    alert = \"Misleading\"\n",
        "    if confidence > 85:\n",
        "        alert = \"True\"\n",
        "    elif confidence > 70:\n",
        "        alert = \"Partially True\"\n",
        "\n",
        "    response = {\n",
        "        \"alert\": alert,\n",
        "        \"confidence\": confidence,\n",
        "        \"summary\": scores[0][0][\"text\"] if scores else \"No summary available.\",\n",
        "        \"source\": scores[0][0][\"source\"] if scores else \"No source available.\"\n",
        "    }\n",
        "\n",
        "    return response\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPsCG9Ejeyyx",
        "outputId": "b2a28b63-ae82-4140-f5ce-f312b1d464c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'alert': 'Partially True', 'confidence': 72, 'summary': \"Narendra Modi is India's first OBC Prime Minister\", 'source': 'https://www.altnews.in/no-narendra-modi-is-not-indias-first-obc-prime-minister/'}\n"
          ]
        }
      ],
      "source": [
        "# Example Usage\n",
        "claim = \"Narendra Modi is the prime minister of India\"\n",
        "result = process_fact_checking_results(claim)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaQ4WVO1fxCW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
